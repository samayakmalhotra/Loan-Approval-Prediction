# -*- coding: utf-8 -*-
"""Loan modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gZHSnV8jGTzVGDdlu_Vlljuk7Fr7k-rl
"""

#Importing Libraries and packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("/content/final dataset1.csv")

#Show all properties on display and set style
pd.set_option('display.max_columns', None)
sns.set_style('whitegrid')
warnings.simplefilter("ignore")

df['gender'] = df['gender'].map({'male':1,'female':0}).astype('int')
df['own_telephone'] = df['own_telephone'].map({'yes':1,'no':0}).astype('int')
df['foreign_worker'] = df['foreign_worker'].map({'yes':1,'no':0}).astype('int')

df.drop(columns=['installment_commitment',"residence_since","property_magnitude","num_dependents","own_telephone"], inplace=True)

df.drop(columns=["age"],inplace=True)

df.head()

# Convert 'False' to 0 and 'True' to 1
cols_to_convert = ['purpose_business', 'purpose_domestic_appliances', 'purpose_education', 'purpose_furniture/equipment',
                   'purpose_new_car', 'purpose_other', 'purpose_radio/television', 'purpose_repairs', 'purpose_retraining',
                   'purpose_used_car', 'female_divorced/separated/married', 'male_divorced/separated',
                   'male_married/widowed', 'male_single', 'job_management_self-employed_highly_qualified/officer',
                   'job_skilled_employee/official', 'job_unemployed/unskilled_nonresident', 'job_unskilled_resident']

for col in cols_to_convert:
    df[col] = df[col].map({False: 0, True: 1})

# Convert 'age_group' values to numerical
age_group_mapping = {'under 25': 1, '25-34': 2, '35-49': 3, '50+': 4}
df['age_group'] = df['age_group'].replace(age_group_mapping)

df.drop(columns=['purpose_business', 'purpose_domestic_appliances', 'purpose_education', 'purpose_furniture/equipment',
                   'purpose_new_car', 'purpose_other', 'purpose_radio/television', 'purpose_repairs', 'purpose_retraining',
                   'purpose_used_car'],inplace=True)

df.drop(columns=['job_management_self-employed_highly_qualified/officer',
                   'job_skilled_employee/official', 'job_unemployed/unskilled_nonresident', 'job_unskilled_resident'],inplace=True)

df.head(10)

X = df.drop('accepted',axis=1)

y = df['accepted']

y

cols = ['credit_amount','duration']
from sklearn.preprocessing import StandardScaler
st = StandardScaler()
X[cols]=st.fit_transform(X[cols])

X

"""Training and Testing"""

from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from sklearn.impute import SimpleImputer

# Create an imputer object
imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', 'constant'

# Fit and transform the data
X = imputer.fit_transform(X)

"""Supervised training algorthims like LR, RF, SVM, Decision tree"""

model_df = {}

def model_val(model, X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"{type(model).__name__} accuracy is {accuracy_score(y_test, y_pred)}")
    score = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    print(f"{type(model).__name__} Avg cross val score is {np.mean(score)}")
    model_df[type(model).__name__] = round(np.mean(score) * 100, 2)

# Create model instances
lr_model = LogisticRegression()
rf_model = RandomForestClassifier()

# Call the model_val function for each model
model_val(lr_model, X, y)
model_val(rf_model, X, y)

# Print the model_df dictionary
print(model_df)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model_val(model,X,y)

from sklearn import svm
model = svm.SVC()
model_val(model,X,y)

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model_val(model,X,y)

"""HyperParam Tuning"""

from sklearn.model_selection import RandomizedSearchCV

log_reg_grid={"C":np.logspace(-4,4,20),
             "solver":['liblinear']}

rs_log_reg=RandomizedSearchCV(LogisticRegression(),
                   param_distributions=log_reg_grid,
                  n_iter=20,cv=5,verbose=True)

rs_log_reg.fit(X,y)

rs_log_reg.best_score_

rs_log_reg.best_params_

"""SVC"""

svc_grid = {'C':[0.25,0.50,0.75,1],"kernel":["linear"]}

rs_svc=RandomizedSearchCV(svm.SVC(),
                  param_distributions=svc_grid,
                   cv=5,
                   n_iter=20,
                  verbose=True)

rs_svc.fit(X,y)

rs_svc.best_score_

rs_svc.best_params_

"""RF Classifier"""

RandomForestClassifier()
rf_grid={'n_estimators':np.arange(10,1000,10),
  'max_features':['auto','sqrt'],
 'max_depth':[None,3,5,10,20,30],
 'min_samples_split':[2,5,20,50,100],
 'min_samples_leaf':[1,2,5,10]
 }
rs_rf=RandomizedSearchCV(RandomForestClassifier(),
                  param_distributions=rf_grid,
                   cv=5,
                   n_iter=20,
                  verbose=True)
rs_rf.fit(X,y)

rs_rf.best_score_

rs_rf.best_params_

"""LogisticRegression score Before Hyperparameter Tuning: 71.4
LogisticRegression score after Hyperparameter Tuning: 71.7
    
------------------------------------------------------
SVC score Before Hyperparameter Tuning: 70.0
SVC score after Hyperparameter Tuning: 71.3
    
--------------------------------------------------------
RandomForestClassifier score Before Hyperparameter Tuning: 72.5
RandomForestClassifier score after Hyperparameter Tuning: 74.9
"""

X = df.drop('accepted',axis=1)
y = df['accepted']

rf = RandomForestClassifier(n_estimators=270,
 min_samples_split=5,
 min_samples_leaf=5,
 max_features='sqrt',
 max_depth=5)

from sklearn.impute import SimpleImputer

# Create an imputer object
imputer = SimpleImputer(strategy='mean')

# Fit and transform the data
X = imputer.fit_transform(X)

rf.fit(X,y)

import joblib
joblib.dump(rf,'loan_status_predict')

model = joblib.load('loan_status_predict')
import pandas as pd

df = pd.DataFrame({
    'checking_status': 0,
    'duration': 6,
    'credit_history': 0,
    'credit_amount': 1169,
    'savings_status':1,
    'employment': 3,
    'other_payment_plans': -1,
    'housing': 1,
    'existing_credits': 2,
    'foreign_worker': 1,
    'gender': 0,
    'age_group': 3,
    'female_divorced/separated/married': 0,
    'male_divorced/separated': 0,
    'male_married/widowed': 0,
    'male_single': 1,

}, index=[0])

df

rf.fit(X,y)

result = model.predict(df)

# Print the prediction
if result == 1:
    print("Loan Approved")
else:
    print("Loan Not Approved")

"""GUI using Tkinter"""

from tkinter import *
import joblib
import pandas as pd

def show_entry():

    p1 = float(e1.get())
    p2 = float(e2.get())
    p3 = float(e3.get())
    p4 = float(e4.get())
    p5 = float(e5.get())
    p6 = float(e6.get())
    p7 = float(e7.get())
    p8 = float(e8.get())
    p9 = float(e9.get())
    p10 = float(e10.get())
    p11 = float(e11.get())
    p12 = float(e12.get())
    p13 = float(e13.get())
    p14 = float(e14.get())
    p15 = float(e15.get())
    p16= float(e16.get())

    model = joblib.load('loan_status_predict')
    df = pd.DataFrame({
    'checking_status': p1,
    'duration': p2,
    'credit_history': p3,
    'credit_amount': p4,
    'savings_status':p5,
    'employment': p6,
    'other_payment_plans': p7,
     'housing': p8,
    'existing_credits': p9,
    'foreign_worker': p10,
    'gender': p11,
    'age_group': p12,
    'female_divorced/separated/married': p13,
    'male_divorced/separated': p14,
    'male_married/widowed':p15,
    'male_single':p16,

},index=[0])
    result = model.predict(df)

    if result == 1:
        Label(master, text="Loan approved").grid(row=31)
    else:
        Label(master, text="Loan Not Approved").grid(row=31)


master =Tk()
master.title("Loan Status Prediction Using Machine Learning")
label = Label(master,text = "Loan Acceptance Prediction",bg = "black",
               fg = "white").grid(row=0,columnspan=2)

Label(master,text = "Checking Status").grid(row=1)
Label(master,text = "Duration ").grid(row=2)
Label(master,text = "Credit History").grid(row=3)
Label(master,text = "Credit Amount").grid(row=4)
Label(master,text = "Savings Status").grid(row=5)
Label(master,text = "Employment[1,2,3,-1]").grid(row=6)
Label(master,text = "Other_payment_plans").grid(row=7)
Label(master,text = "Housing").grid(row=8)
Label(master,text = "Existing_credits").grid(row=9)
Label(master,text = "Foreign_worker").grid(row=10)
Label(master,text = "Gender").grid(row=11)
Label(master,text = "Age group[1,2,3,4]").grid(row=12)
Label(master,text = "Female_divorced/separated/married").grid(row=13)
Label(master,text = "Male_divorced/separated").grid(row=14)
Label(master,text = "Male_married/widowed").grid(row=15)
Label(master,text = "Male_single").grid(row=16)

e1 = Entry(master)
e2 = Entry(master)
e3 = Entry(master)
e4 = Entry(master)
e5 = Entry(master)
e6 = Entry(master)
e7 = Entry(master)
e8 = Entry(master)
e9 = Entry(master)
e10 = Entry(master)
e11 = Entry(master)
e12= Entry(master)
e13=Entry(master)
e14=Entry(master)
e15=Entry(master)
e16=Entry(master)


e1.grid(row=1,column=1)
e2.grid(row=2,column=1)
e3.grid(row=3,column=1)
e4.grid(row=4,column=1)
e5.grid(row=5,column=1)
e6.grid(row=6,column=1)
e7.grid(row=7,column=1)
e8.grid(row=8,column=1)
e9.grid(row=9,column=1)
e10.grid(row=10,column=1)
e11.grid(row=11,column=1)
e12.grid(row=12,column=1)
e13.grid(row=13,column=1)
e14.grid(row=14,column=1)
e15.grid(row=15,column=1)
e16.grid(row=16,column=1)

Button(master,text="Predict",command=show_entry).grid()

mainloop()